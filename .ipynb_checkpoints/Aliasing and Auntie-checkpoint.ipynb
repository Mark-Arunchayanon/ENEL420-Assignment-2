{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import animation\n",
    "import scipy.signal as signal\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Audio, display, HTML\n",
    "from ipywidgets import interact\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import requests\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['animation.writer'] = 'avconv'\n",
    "matplotlib.rcParams['figure.figsize'] = \"8,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 5      # the sampling frequency\n",
    "F_plot = 100  # the frequency used for plotting the time-continuous curves\n",
    "T = 2       # the time-span we'll cover\n",
    "t = np.arange(0, T, 1/Fs)  # the sample times\n",
    "t_plot = np.arange(0, t.max(), 1/F_plot)  # time instants for plotting\n",
    "\n",
    "\n",
    "def showAlias(f1):\n",
    "    plt.gcf().clear()\n",
    "    f2 = min(f1, Fs-f1)  # determine the alias frequency\n",
    "    xt1 = lambda t: np.cos(2*np.pi*f1*t) # create both sine-functions\n",
    "    xt2 = lambda t: np.cos(2*np.pi*f2*t)\n",
    "    \n",
    "    # plot the signals\n",
    "    plt.subplot(121)\n",
    "    plt.plot(t_plot, xt1(t_plot), 'b-', lw=2, label='input signal')\n",
    "    plt.stem(t, xt1(t), label='sampled points')\n",
    "    plt.plot(t_plot, xt2(t_plot), 'g-', label='after sampling')\n",
    "    plt.ylim((-1.1, 1.5)); plt.grid(True)\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.xlabel('$t$'); plt.ylabel('$x(t), x[n]$')\n",
    "    \n",
    "    # plot the spectrum of the signals\n",
    "    t_freq = np.arange(0, 20*T, 1/F_plot) \n",
    "    x1 = xt1(t_freq)\n",
    "    x2 = xt2(t_freq)\n",
    "    X1 = np.fft.fftshift(np.fft.fft(x1, 8*len(x1))) / len(x1)\n",
    "    X2 = np.fft.fftshift(np.fft.fft(x2, 8*len(x1))) / len(x2)\n",
    "    f = np.linspace(-F_plot/2, F_plot/2, len(X1), endpoint=False)\n",
    "    plt.subplot(122)\n",
    "    plt.plot(f, abs(X1), lw=2, label='input')\n",
    "    plt.plot(f, abs(X2), label='after sampling')\n",
    "    plt.legend(loc='upper left', fontsize=8)\n",
    "    plt.xlim((-Fs, Fs))\n",
    "    plt.axvline(-Fs/2, color='k', ls='--', lw=2)\n",
    "    plt.axvline(Fs/2, color='k', ls='--', lw=2)\n",
    "    plt.ylim((-0.1, 1.1))\n",
    "    plt.grid(True)\n",
    "    plt.text(x=2.5, y=0.8, s='$f_{in}=%.2f$\\n$f_{out}=%.2f$' % (f1, f2), bbox=dict(facecolor='white'))\n",
    "    plt.xlabel('$f$'); plt.ylabel('$|X(f)|$')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def presentAliasingAudio(original, rate, factor):\n",
    "    down_aliased = original[::factor] # dumb downsampling, no anti-aliasing\n",
    "\n",
    "    b = signal.firwin(155, 1.0/factor-0.01); a=1  # design the AAF\n",
    "    lowpass = signal.lfilter(b, a, original)      # apply the AAF\n",
    "    down_nonaliased = lowpass[::factor]           # perform Downsampling\n",
    "\n",
    "    display(HTML(\"Original:\"), Audio(data=original, rate=rate))\n",
    "    display(HTML(\"With Aliasing:\"), Audio(data=down_aliased, rate=rate/factor))\n",
    "    display(HTML(\"Without Aliasing:\"), Audio(data=down_nonaliased,rate=rate/factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAudio(url, start, length):\n",
    "    R = requests.get(url)\n",
    "    with open(\"sound.mp3\", \"wb\") as f:\n",
    "        f.write(R.content)\n",
    "    !ffmpeg -y -i sound.mp3 sound.wav > /dev/null\n",
    "    rate, data = wavfile.read(\"sound.wav\")\n",
    "    if len(data.shape) > 1:\n",
    "        data = data.sum(axis=1)\n",
    "    data = (1.0 * data / abs(data).max()).astype(np.float32)\n",
    "    \n",
    "    return rate, data[rate*start+np.arange(rate*length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_voice = \"http://ia800200.us.archive.org/21/items/adventures_of_dog_1101_librivox/adventuresofadog_00_elwes.mp3\"\n",
    "url_music = \"http://www.scientificinvesting.eu/a/Mozart%20-%20Symphony%20n.10%20K.74%20in%20G%20-%201%20Allegro.mp3\"\n",
    "rate_voice, data_voice = loadAudio(url_voice, 40, 10)\n",
    "rate_music, data_music = loadAudio(url_music, 40, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "interact(showAlias, f1=(0,5., 0.01));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presentAliasingAudio(data_chirp, rate_chirp, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 4  # the downsampling factor\n",
    "b = signal.firwin(155, 1.0/factor-0.01); a=1  # design the filter\n",
    "w, H = signal.freqz(b, a) # calculate frequency response\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.stem(b)\n",
    "plt.grid(True); plt.title('Impulse response')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(w/np.pi, 20*np.log10(abs(H)))\n",
    "plt.grid(True)\n",
    "plt.xticks([0, 1/factor, 1]);\n",
    "plt.ylim((-80, 10)); plt.title(\"Magnitude response\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'presentAliasingAudio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c7d966666455>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# to call this function, the code below needs to be executed before\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpresentAliasingAudio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_voice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate_voice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'presentAliasingAudio' is not defined"
     ]
    }
   ],
   "source": [
    "# to call this function, the code below needs to be executed before\n",
    "presentAliasingAudio(data_voice, rate_voice, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'presentAliasingAudio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5376693956c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpresentAliasingAudio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_music\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate_music\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'presentAliasingAudio' is not defined"
     ]
    }
   ],
   "source": [
    "presentAliasingAudio(data_music, rate_music, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 44100\n",
    "t = np.arange(0, 10, 1/Fs)\n",
    "f = 200\n",
    "data_chirp = np.sin(2*np.pi*f*t*t)\n",
    "rate_chirp = Fs\n",
    "presentAliasingAudio(data_chirp, rate_chirp, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
